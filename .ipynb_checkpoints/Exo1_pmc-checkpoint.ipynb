{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20464d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0bc731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lecture des donnees à partir fichier txt \n",
    "data = []\n",
    "file = open(\"imdb_labelled.txt\", \"r\")\n",
    "for review in file:\n",
    "    x = review.strip().split('\\t')  \n",
    "    data.append([x[0], int(x[1])]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb5b18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The rest of the movie lacks art, charm, meanin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wasted two hours.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Saw the movie today and thought it was a good ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A bit predictable.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Loved the casting of Jimmy Buffet as the scien...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1\n",
       "5  The rest of the movie lacks art, charm, meanin...          0\n",
       "6                                Wasted two hours.            0\n",
       "7  Saw the movie today and thought it was a good ...          1\n",
       "8                               A bit predictable.            0\n",
       "9  Loved the casting of Jimmy Buffet as the scien...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reprisentation sous forme un tableau\n",
    "df = pd.DataFrame(data, columns=['review', 'sentiment']) \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c449fe21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# description du tableau: 1000 lignes, 2 colonnes\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb001794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tableau contient 500 review negatifs et 500 positifs\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db20638d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk #Natural Language Toolkit\n",
    "import re #regex\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "ps=nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "revs = df.review.copy() #liste des phrases\n",
    "senti=df.sentiment.copy() #liste des sentiments\n",
    "\n",
    "i=0\n",
    "positiveTokens= [] # tokens du review  positif\n",
    "negativeTokens= [] # tokens du review  negatif\n",
    "\n",
    "#Exploration et tokeniser un review\n",
    "def tokenize(phrase): \n",
    "    phrase = re.sub('[^a-zA-Z]', ' ', phrase).lower().split() #supprimer les caractères speciaux\n",
    "    phrase = [nltk.WordNetLemmatizer().lemmatize(word) for word in phrase if not word in stopwords.words('english')] #lemmatizing\n",
    "    phrase = ' '.join(phrase)\n",
    "    phrase=word_tokenize(phrase) #tokenizing (phrase to array of words)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a024956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separerles  positifs et negatifs tokens\n",
    "for rev in revs:    \n",
    "    if senti[i]==0:\n",
    "        negativeTokens.append(tokenize(rev)) #tableau de negatif tokens\n",
    "    else:\n",
    "        positiveTokens.append(tokenize(rev)) #tableau de positif tokens\n",
    "    i+=1\n",
    "\n",
    "positiveTokens=(np.concatenate((positiveTokens), axis=0)) #  list de tout les positifs tokens\n",
    "negativeTokens=(np.concatenate((negativeTokens), axis=0)) # list de tout les negatifs tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05fefb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>positive Freq</th>\n",
       "      <th>negative Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>circumstance</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>though</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thoroughly</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>escalating</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cutting</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  positive Freq  negative Freq\n",
       "0  circumstance              1              0\n",
       "1        though              7              4\n",
       "2    thoroughly              3              0\n",
       "3    escalating              1              0\n",
       "4       cutting              1              0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordFreq=[]\n",
    "\n",
    "#calculater frequence d'un mot (Number of occurences of a word in Tokens)\n",
    "def wordFrequency(word,array): \n",
    "    wordFreq=np.count_nonzero(array==word)\n",
    "    return wordFreq\n",
    "\n",
    "#--------------------- VISUALISATION-------------------------\n",
    "#create dataframe of [word,posFreq,negFreq]\n",
    "for word in list(set(np.concatenate((positiveTokens,negativeTokens), axis=0))):\n",
    "    WordFreq.append([word,wordFrequency(word,positiveTokens),wordFrequency(word,negativeTokens)]) #[word,posFreq,negFreq]\n",
    "wordFreqDF = pd.DataFrame(WordFreq, columns=['word','positive Freq', 'negative Freq'])\n",
    "wordFreqDF.head()\n",
    "#---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e17a63a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>PosF</th>\n",
       "      <th>NegF</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>117</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>166</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>160</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>MANNA FROM HEAVEN is a terrific film that is b...</td>\n",
       "      <td>150</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The scenes are often funny and occasionally to...</td>\n",
       "      <td>89</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The cast of veteran actors are more than just ...</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Ursula Burton's portrayal of the nun is both t...</td>\n",
       "      <td>62</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>If you are looking for a movie with a terrific...</td>\n",
       "      <td>276</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  PosF  NegF  sentiment\n",
       "0   A very, very, very slow-moving, aimless movie ...   117   124          0\n",
       "1   Not sure who was more lost - the flat characte...    42    40          0\n",
       "2   Attempting artiness with black & white and cle...   166   248          0\n",
       "3        Very little music or anything to speak of.      19    23          0\n",
       "4   The best scene in the movie was when Gerardo i...   160   145          1\n",
       "..                                                ...   ...   ...        ...\n",
       "95  MANNA FROM HEAVEN is a terrific film that is b...   150   105          1\n",
       "96  The scenes are often funny and occasionally to...    89    59          1\n",
       "97  The cast of veteran actors are more than just ...    36    14          1\n",
       "98  Ursula Burton's portrayal of the nun is both t...    62    34          1\n",
       "99  If you are looking for a movie with a terrific...   276   202          1\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataSet=[]\n",
    "  \n",
    "#calculate row of dataset [review,PosF,NegF,sentiment]\n",
    "def phraseFreq(phrase,sentiment):  \n",
    "    Posfreq=0\n",
    "    Negfreq=0\n",
    "    for word in tokenize(phrase):\n",
    "        Posfreq+=wordFrequency(word,positiveTokens) #la somme des frequences positifs\n",
    "        Negfreq+=wordFrequency(word,negativeTokens) #la somme des frequences negatifs\n",
    "\n",
    "    return [phrase,Posfreq,Negfreq,sentiment]\n",
    "\n",
    "\n",
    "#convert review(input) to vector(PosF,NegF)\n",
    "def review2vec(review):\n",
    "    Posfreq=0\n",
    "    Negfreq=0\n",
    "    for word in tokenize(phrase):\n",
    "        Posfreq+=wordFrequency(word,positiveTokens)\n",
    "        Negfreq+=wordFrequency(word,negativeTokens)\n",
    "    return [Posfreq,Negfreq]\n",
    "\n",
    "\n",
    "def createDataSet():\n",
    "    i=0\n",
    "    for rev in revs:\n",
    "        DataSet.append(phraseFreq(rev,senti[i]))\n",
    "        i+=1\n",
    "\n",
    "createDataSet()\n",
    "\n",
    "DataSet=pd.DataFrame(DataSet, columns=['review','PosF', 'NegF','sentiment'])\n",
    "DataSet.head(100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da8b12bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import datasets\n",
    "import seaborn as sns  # Bibliothèque pour la visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21304fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117. 124.] 0\n"
     ]
    }
   ],
   "source": [
    "# Données + classes cibles\n",
    "data   = np.array(DataSet.values[:,1:3], dtype=np.float32)\n",
    "target = DataSet.values[:,-1]\n",
    "print(data[0],target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "979c27a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Partition aléatoire de l’échantillon\n",
    "# 10%=100 exemples pour le test\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, target, test_size=0.1)\n",
    "\n",
    "len(testY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fa5b712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformer l'étiquette(sentiments) en un vecteur binaire : 3 --> (0,0,0,1,0,0,0,0,0,0)\n",
    "trainYC = np.array(list(map(lambda x: [1,0] if x == 1 else [0,1], trainY)))\n",
    "testYC = np.array(list(map(lambda x: [1,0] if x == 1 else [0,1], testY)))\n",
    "\n",
    "\n",
    "trainYC\n",
    "\n",
    "# review => network => [0.82,0.18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "334d4929",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron:\n",
    "    \n",
    "    def __init__(self, arch , alpha = 0.1):\n",
    "        # poids + biais\n",
    "        self.W = {}\n",
    "        self.B = {}\n",
    "        \n",
    "        # Taux d'adaptation\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # Architecture :nbre de couches et nombre de neurones par couche\n",
    "        self.arch = arch\n",
    "        \n",
    "        # Initialisation des poids: valeurs issues d'une distribution normale\n",
    "        for i in np.arange(1,len(self.arch)):  \n",
    "            # Poids\n",
    "            w = np.random.randn(self.arch[i], self.arch[i-1])\n",
    "            self.W[i] = w/np.sqrt(self.arch[i])\n",
    "            # Bias\n",
    "            b = np.random.randn(self.arch[i],1)\n",
    "            self.B[i] = b/np.sqrt(self.arch[i])            \n",
    "            \n",
    "            \n",
    "    def sigmoid(self, x):\n",
    "        return 1.0/(1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def dsigmoid(self, x): # x correspond ici à sigmoid(uj(t)), voir le cours\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    \n",
    "    #Calcul et mémorisation de l'état de tous les neurones du réseau \n",
    "    def forward_pass(self, x):\n",
    "        a = np.atleast_2d(x).T\n",
    "        \n",
    "        stats = {}\n",
    "        stats[0] = a\n",
    "        for layer in np.arange(1, len(self.arch)):\n",
    "            a = self.sigmoid(np.dot(self.W[layer], a) + self.B[layer])\n",
    "            stats[layer] = a\n",
    "        return stats    \n",
    "    \n",
    "    \n",
    "    #Sortie du réseau associée à une entrée X (les états des autres neurones ne sont pas mémorisés)\n",
    "    def predict(self, X):\n",
    "        a = np.atleast_2d(X).T\n",
    "        for layer in np.arange(1, len(self.arch)):\n",
    "            a = self.sigmoid(np.dot(self.W[layer], a) + self.B[layer])\n",
    "        return a\n",
    "    \n",
    "    \n",
    "    #Calcul de l'erreur quadratique moyenne\n",
    "    def quadratic_loss(self, X, Y):\n",
    "        Y = np.atleast_2d(Y).T\n",
    "        predictions = self.predict(X)\n",
    "        n = X.shape[0]\n",
    "        loss = (1/n) * 0.5 * np.sum((predictions - Y) ** 2) \n",
    "        return loss \n",
    "    \n",
    "    \n",
    "    #Calcul des gradients locaux \n",
    "    def compute_gradient(self, x, y):\n",
    "     \n",
    "        L = len(self.arch) - 1 # indice de la couche de sortie \n",
    "        # Gradients\n",
    "        Gw = {}\n",
    "        Gb = {}\n",
    "        A = self.forward_pass(x)\n",
    "        # Les vecteurs delta  \n",
    "        D = {}\n",
    "        y = np.atleast_2d(y).T\n",
    "        deltaL = (A[L] - y) * self.dsigmoid(A[L])\n",
    "        D[L] = deltaL # Pour la sortie \n",
    "        \n",
    "        # Calculer les vecteurs delta des autres couches en utilisants les vecteurs delta de la couche suivante\n",
    "        for l in np.arange(L-1, 0, -1):\n",
    "            D[l] = (self.W[l+1].T.dot(D[l+1])) * self.dsigmoid(A[l])\n",
    "        \n",
    "        for l in np.arange(L, 0, -1):\n",
    "            Gb[l] = D[l]\n",
    "            Gw[l] = D[l].dot(A[l-1].T)        \n",
    "       \n",
    "        return (Gw, Gb)\n",
    "    \n",
    "    \n",
    "    # Mise à jour par rapport à l'erreur moyenne (relative à un bloc d'exemples)\n",
    "    def update_with_bloc(self, bloc):\n",
    "      \n",
    "        m = len(bloc)\n",
    "        # Gradients locaux\n",
    "        GCw = {}\n",
    "        GCb = {}\n",
    "        # Initialiser à zeros \n",
    "        for i in np.arange(1,len(self.arch)):\n",
    "            GCw[i] = np.zeros(self.W[i].shape)\n",
    "            GCb[i] = np.zeros(self.B[i].shape)\n",
    "            \n",
    "        # Calcul des gradients\n",
    "        for x, y in bloc:\n",
    "            Gw, Gb = self.compute_gradient(x, y)\n",
    "            for i in np.arange(1,len(self.arch)): \n",
    "                GCw[i] += Gw[i]\n",
    "                GCb[i] += Gb[i]\n",
    "                \n",
    "        # Mettre à jour les poids \n",
    "        for l in np.arange(1,len(self.arch)):\n",
    "            self.W[l] = self.W[l] - (self.alpha/m)*(GCw[l])\n",
    "            self.B[l] = self.B[l] - (self.alpha/m)*(GCb[l])\n",
    "    \n",
    "    \n",
    "    # Iteration: entrainement en utilisant tous les exemples, un bloc de taille bloc_size chaque fois\n",
    "    def train(self, D, bloc_size):\n",
    "        train_size = len(D)\n",
    "        np.random.shuffle(D) # tirage au sort\n",
    "        \n",
    "        # Bloc d'exemples\n",
    "        blocs = [D[k : k + bloc_size] for k in range(0, train_size, bloc_size)]\n",
    "        \n",
    "        for bloc in blocs: # Mise à jour suite au passage de chaque bloc\n",
    "            self.update_with_bloc(bloc)\n",
    "  \n",
    "\n",
    "    # Apprentissage\n",
    "    def fit(self, X, Y, bloc_size = 20, iterations = 10000, error_min = 0.001, displayPeriod = 5000):\n",
    "     \n",
    "        # Exemples avec X et Y Assemblés\n",
    "        D = list(zip(X,Y))\n",
    "        \n",
    "        # Erreurs\n",
    "        errors = [self.quadratic_loss(X,Y)]   # Erreur initiale    \n",
    "        \n",
    "        iter = 0\n",
    "        print(\"Itération: {}-{}, Erreur: {:.6f}\".format(iter, iterations,errors[iter]))\n",
    "        while iter < iterations and errors[iter] > error_min: # Tour de boucle \n",
    "            \n",
    "            self.train(D, bloc_size)  # Mettre à jour \n",
    "            errors.append(self.quadratic_loss(X,Y))         # Nouvelle erreur\n",
    "          \n",
    "            if (iter+1) % displayPeriod == 0:\n",
    "                print(\"Itération: {}-{}, Error: {:.6f}\".format(iter + 1, iterations,errors[iter]))\n",
    "            iter += 1\n",
    "        \n",
    "        if errors[iter] < error_min: # Erreur inférieur à la valeur minimale\n",
    "            print(\"Fin: erreur minimale atteinte : {:.6f}.\", errors[iter])\n",
    "        elif iter == iterations:\n",
    "            print(\"Fin: nombre maximum d'itérations atteint.\")\n",
    "       \n",
    "        return (errors, iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "752f5f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itération: 0-500, Erreur: 0.312079\n",
      "Itération: 20-500, Error: 0.126998\n",
      "Itération: 40-500, Error: 0.121924\n",
      "Itération: 60-500, Error: 0.122278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nessm\\AppData\\Local\\Temp/ipykernel_17000/1717125781.py:25: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itération: 80-500, Error: 0.128319\n",
      "Itération: 100-500, Error: 0.127972\n",
      "Itération: 120-500, Error: 0.123550\n",
      "Itération: 140-500, Error: 0.124651\n",
      "Itération: 160-500, Error: 0.130530\n",
      "Itération: 180-500, Error: 0.117466\n",
      "Itération: 200-500, Error: 0.120643\n",
      "Itération: 220-500, Error: 0.135514\n",
      "Itération: 240-500, Error: 0.122992\n",
      "Itération: 260-500, Error: 0.126822\n",
      "Itération: 280-500, Error: 0.119017\n",
      "Itération: 300-500, Error: 0.127216\n",
      "Itération: 320-500, Error: 0.122322\n",
      "Itération: 340-500, Error: 0.125588\n",
      "Itération: 360-500, Error: 0.129141\n",
      "Itération: 380-500, Error: 0.120178\n",
      "Itération: 400-500, Error: 0.133173\n",
      "Itération: 420-500, Error: 0.121170\n",
      "Itération: 440-500, Error: 0.119994\n",
      "Itération: 460-500, Error: 0.120578\n",
      "Itération: 480-500, Error: 0.122700\n",
      "Itération: 500-500, Error: 0.121332\n",
      "Fin: nombre maximum d'itérations atteint.\n"
     ]
    }
   ],
   "source": [
    "# Initialisation et apprentissage\n",
    "# trainX.shape[1]\n",
    "# testY\n",
    "pmc = MultiLayerPerceptron(arch=[trainX.shape[1],15,15,2], alpha=0.1)\n",
    "(errs, iter_fin) = pmc.fit(trainX, trainYC, iterations=500, bloc_size=5, error_min=0.00001, displayPeriod=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fb668db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19. 82.]\n",
      "0\n",
      "Sortie prédite : \n",
      "[[0.0078542 ]\n",
      " [0.99217033]])\n"
     ]
    }
   ],
   "source": [
    "# Test pour un exemple \n",
    "# data.shape[0]\n",
    "randIndex = np.random.randint(0,data.shape[0]-1,1)[0]\n",
    "# print('Exemple : '+str(randIndex)+', classe réelle : '+str(target[randIndex]))\n",
    "print(testX[7])\n",
    "print(testY[7])\n",
    "# # print(data[randIndex])\n",
    "print('Sortie prédite : \\n'+str(pmc.predict(testX[7]))+')' )\n",
    "# testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a5a5bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '1', '1', '0', '1', '0', '1', '1', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '1', '0', '1', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '0', '0', '1', '0', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "targetTestR = ['']*(np.array(testY).shape[0])\n",
    "\n",
    "# targetTestR\n",
    "for index in range(testX.shape[0]):     \n",
    "    o = np.round(pmc.predict(testX[index]),0)[:,0].astype(int)\n",
    "    if((o==np.array([1,0])).all()):\n",
    "        targetTestR[index] = 1\n",
    "    elif((o==np.array([0,1])).all()):\n",
    "        targetTestR[index] = 0\n",
    "\n",
    "        \n",
    "# Sortie calculée et sortie réelle pour la base de test      \n",
    "targetTestRF=list(map(lambda x: '1' if x == 1 else '0', targetTestR))\n",
    "# print(targetTestR)\n",
    "testYF=list(map(lambda x: '1' if x == 1 else '0', testY))\n",
    "print(testYF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f99edacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Taux de la classification correcte \n",
    "metrics.accuracy_score(testYF, targetTestRF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8f4ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
